{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "img-res-autoencoder",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cMecdAkGQ2J8ljdCvfBHh1x52JARW0AX",
      "authorship_tag": "ABX9TyMHISwATPh3JbuqDguC1D/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainmaker29/autoencoder-img-res/blob/master/img_res_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1OvDRrlh_-G",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMagE5FVHWPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Conv2D,MaxPooling2D,Dropout,Conv2DTranspose\n",
        "from tensorflow.keras.layers import UpSampling2D,add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys42lsj2iCwh",
        "colab_type": "text"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaALZNnIIYPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(256,256,3))\n",
        "\n",
        "l1 = Conv2D(64,(3,3),padding=\"same\",activation='relu',activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
        "l2 = Conv2D(64,(3,3),padding=\"same\",activation='relu',activity_regularizer=regularizers.l1(10e-10))(l1)\n",
        "l3= MaxPooling2D(padding='same')(l2)\n",
        "l4 = Dropout(0.3)(l3)\n",
        "l5 = Conv2D(128, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
        "l6 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l5)\n",
        "l7 = MaxPooling2D(padding='same')(l6)\n",
        "l8 = Conv2D(256, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l7)\n",
        "encoder= Model(input_img,l8)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V07aJJzah4g7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "6cce9294-3675-414b-887d-74c8ad5b4c32"
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 64, 64, 256)       295168    \n",
            "=================================================================\n",
            "Total params: 555,328\n",
            "Trainable params: 555,328\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwvE5gCWjU1T",
        "colab_type": "text"
      },
      "source": [
        "# Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJh06oYah9JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_img = Input(shape=(256, 256, 3))\n",
        "l1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
        "l2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
        "\n",
        "l3 = MaxPooling2D(padding='same')(l2)\n",
        "l3 = Dropout(0.3)(l3)\n",
        "l4 = Conv2D(128, (3, 3),  padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
        "l5 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
        "\n",
        "l6 = MaxPooling2D(padding='same')(l5)\n",
        "l7 = Conv2D(256, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
        "\n",
        "l8 = UpSampling2D()(l7)\n",
        "l9 = Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "            activity_regularizer=regularizers.l1(10e-10))(l8)\n",
        "l10 = Conv2D(128, (3, 3), padding='same', activation='relu',\n",
        "             activity_regularizer=regularizers.l1(10e-10))(l9)\n",
        "\n",
        "l11 = add([l5, l10])\n",
        "l12 = UpSampling2D()(l11)\n",
        "l13 = Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "             activity_regularizer=regularizers.l1(10e-10))(l12)\n",
        "l14 = Conv2D(64, (3, 3), padding='same', activation='relu',\n",
        "             activity_regularizer=regularizers.l1(10e-10))(l13)\n",
        "\n",
        "l15 = add([l14, l2])\n",
        "\n",
        "decoder = Conv2D(3,(3,3),padding='same',activation='relu',activity_regularizer=regularizers.l1(10e-10))(l15)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDnNxxWBkQdq",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXwm1lMhkOxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = Model(input_img,decoder)\n",
        "#fenn\n",
        "autoencoder_hfenn = Model(input_img,decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOYncskumB_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "bda2d483-1a5d-4919-eab8-10ea9ffbed5c"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 256, 256, 64) 1792        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128, 128, 64) 0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 128 73856       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 128, 128, 128 295040      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 128, 128, 128 147584      conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 128, 128, 128 0           conv2d_18[0][0]                  \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 256, 256, 64) 73792       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 256, 256, 64) 0           conv2d_23[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 256, 256, 3)  1731        add_3[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,110,403\n",
            "Trainable params: 1,110,403\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeOkIAaJmERm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta',loss='mean_squared_error')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjoxm5njsyrE",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaJNMjMgm5u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "from scipy import ndimage, misc\n",
        "from skimage.transform import resize, rescale\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "def train_batches(just_load=False):\n",
        "  batches=5\n",
        "  batch=0  # Counter - no. of images in current batch,inc and then resets per batch\n",
        "  batch_nb=0 #batch index\n",
        "\n",
        "  max_batches=-1\n",
        "\n",
        "  epochs=4\n",
        "\n",
        "\n",
        "\n",
        "  images=[]\n",
        "  x_train_n=[]\n",
        "  x_train_down=[]\n",
        "\n",
        "  x_train_n2=[] #resulting high res dataset\n",
        "  x_train_down2=[] #resulting low res dataset\n",
        "\n",
        "  for root, dirnames, filenames in os.walk(\"/drive/My Drive/image_resolution/\"):\n",
        "    for filename in filenames:\n",
        "      if re.search(\"\\.(jpg|jpeg|JPEG|png|bmp|tiff)$\", filename):\n",
        "        if batch_nb == max_batches:\n",
        "          # If we limit the number of batches, just return earlier\n",
        "          return x_train_n2, x_train_down2\n",
        "        filepath = os.path.join(root, filename)\n",
        "        image = pyplot.imread(filepath)\n",
        "        if len(image.shape) > 2:\n",
        "          image_resized = resize(image, (256, 256)) # Resize the image so that every image is the same size\n",
        "          x_train_n.append(image_resized) # Add this image to the high res dataset\n",
        "          x_train_down.append(rescale(rescale(image_resized, 0.5), 2.0)) # Rescale it 0.5x and 2x so that it is a low res image but still has 256x256 resolution\n",
        "          batch += 1\n",
        "          if batch == batches:\n",
        "            batch_nb += 1\n",
        "\n",
        "            x_train_n2 = np.array(x_train_n)\n",
        "            x_train_down2 = np.array(x_train_down)\n",
        "                        \n",
        "            if just_load_dataset:\n",
        "              return x_train_n2, x_train_down2\n",
        "                        \n",
        "            print('Training batch', batch_nb, '(', batches, ')')\n",
        "\n",
        "            autoencoder.fit(x_train_down2, x_train_n2,\n",
        "                            epochs=ep,\n",
        "                            batch_size=10,\n",
        "                            shuffle=True,\n",
        "                            validation_split=0.15)\n",
        "                    \n",
        "            x_train_n = []\n",
        "            x_train_down = []\n",
        "                    \n",
        "            batch = 0\n",
        "\n",
        "  return x_train_n2, x_train_down2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rF6JzKyvBL7",
        "colab_type": "text"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J12S7LjkuE0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_n, x_train_down = train_batches(just_load=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1QppByxvFJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.load_weights(\"/content/drive/My Drive/img_res/sr.img_net.mse_hfenn.final_model5_2.no_patch.weights.best.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnF0_UJqv_6_",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsVVFabMvX4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.load_weights('/content/drive/My Drive/img_res/encoder_weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Q8iC0jwIP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "913eccdd-6c8a-4b9e-d8ca-eec063ed8f8f"
      },
      "source": [
        "encoded_imgs = encoder.predict(x_train_down)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-dc602f30733a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_down\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0;34m\"\"\"Selects a data adapter than can handle a given x and y.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mALL_ADAPTER_CLS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mcan_handle\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    617\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m     \u001b[0mhandles_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m     \u001b[0mhandles_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_is_list_of_scalars\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_list_of_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W07rjtZiwLq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}